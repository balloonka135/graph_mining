{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import linkpred\n",
    "from sklearn import neighbors, datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "df = pd.read_csv('imdb.csv')\n",
    "\n",
    "data_sample1 = defaultdict(list)\n",
    "data_sample2 = defaultdict(list)  # data sample for 2016 movies \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    actors = row['Actors'].split(',')\n",
    "    year = row['Year']\n",
    "    for actor in actors:\n",
    "        if year < 2016:\n",
    "            data_sample1[actor].append(row['Title'])\n",
    "        else:\n",
    "            data_sample2[actor].append(row['Title'])\n",
    "            \n",
    "            \n",
    "G_coeffs = nx.Graph(name=\"Graph for coefficients\")\n",
    "G_y = nx.Graph(name=\"Graph for Y\")\n",
    "\n",
    "# generating coefficients graph\n",
    "for actor in data_sample1:\n",
    "    movies = data_sample1[actor]\n",
    "    actor = actor.strip()\n",
    "    G_coeffs.add_node(actor, actor_attributes=movies)\n",
    "\n",
    "    for node, attrs in G_coeffs.nodes(data=True):\n",
    "        if node != actor:\n",
    "            for a in attrs['actor_attributes']:\n",
    "                if a in movies and not G_coeffs.has_edge(actor, node):\n",
    "                    G_coeffs.add_edge(actor, node, film=a)\n",
    "                \n",
    "# generate Y graph\n",
    "for actor in data_sample2:\n",
    "    movies = data_sample2[actor]\n",
    "    actor = actor.strip()\n",
    "    G_y.add_node(actor, actor_attributes=movies)\n",
    "\n",
    "    for node, attrs in G_y.nodes(data=True):\n",
    "        if node != actor:\n",
    "            for a in attrs['actor_attributes']:\n",
    "                if a in movies and not G_y.has_edge(actor, node):\n",
    "                    G_y.add_edge(actor, node, film=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole dataset 710758 rows in train data and 304609 rows in test data, all features\n",
    "indexes = []\n",
    "degree_src = []  # degree centrality\n",
    "degree_dst = []\n",
    "clos_src = []  # closenness centrality\n",
    "clos_dst = []\n",
    "betw_src = []  # betweenness centrality\n",
    "betw_dst = []\n",
    "\n",
    "d = nx.betweenness_centrality(G_coeffs, normalized=True)\n",
    "\n",
    "for u, v, p in nx.jaccard_coefficient(G_coeffs):\n",
    "    indexes.append(tuple((u, v)))\n",
    "    degree_src.append(nx.degree(G_coeffs, u))\n",
    "    degree_dst.append(nx.degree(G_coeffs, v))\n",
    "    clos_src.append(nx.closeness_centrality(G_coeffs, u))\n",
    "    clos_dst.append(nx.closeness_centrality(G_coeffs, v))\n",
    "    betw_src.append(d[u])\n",
    "    betw_dst.append(d[v])\n",
    "                    \n",
    "edge_df = pd.DataFrame(index=indexes)\n",
    "edge_df['Jaccard'] = [i[2] for i in nx.jaccard_coefficient(G_coeffs, edge_df.index)]\n",
    "edge_df['Adamic-Adar'] = [i[2] for i in nx.adamic_adar_index(G_coeffs, edge_df.index)]\n",
    "edge_df['Pref-Attach'] = [i[2] for i in nx.preferential_attachment(G_coeffs, edge_df.index)]\n",
    "edge_df['Res-Alloc'] = [i[2] for i in nx.resource_allocation_index(G_coeffs, edge_df.index)]\n",
    "edge_df['Degree_centrality'] = [min(i, j) for i, j in zip(degree_src, degree_dst)]\n",
    "edge_df['Closeness_centrality'] = [min(i, j) for i, j in zip(clos_src, clos_dst)]\n",
    "edge_df['Betweenness_ centrality'] = [min(i, j) for i, j in zip(betw_src, betw_dst)]\n",
    "edge_df['Y'] = [1 if G_y.has_edge(u, v) else 0 for u, v in indexes]\n",
    "\n",
    "train, test = train_test_split(edge_df, test_size=0.3) \n",
    "features = ['Jaccard', 'Adamic-Adar', 'Pref-Attach', 'Res-Alloc', 'Degree_centrality', 'Closeness_centrality', 'Betweenness_ centrality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 1000 from the whole train dataset, all features\n",
    "data_class_0 = train[train['Y'] == 0][:1000]  # slice only 1000 rows \n",
    "data_class_1 = train[train['Y'] == 1]\n",
    "df_1000 = data_class_0.append(data_class_1)  # reduced train set with 1000 '0' rows and all '1' rows\n",
    "X_train = df_1000.loc[:, features].values\n",
    "y_train = df_1000.loc[:,['Y']].values\n",
    "X_test = test.loc[:, features].values\n",
    "y_test = test.loc[:,['Y']].values\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn for the 1000 dataset\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn_1000 = knn.predict(X_test)\n",
    "y_pred_proba_knn_1000 = knn.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_knn_1000 = accuracy_score(y_test, y_pred_knn_1000)\n",
    "recall_knn_1000 = recall_score(y_test, y_pred_knn_1000)\n",
    "prec_knn_1000 = precision_score(y_test, y_pred_knn_1000)\n",
    "cm_knn_1000 = confusion_matrix(y_test, y_pred_knn_1000)\n",
    "auc_knn_1000 = roc_auc_score(y_test, y_pred_proba_knn_1000)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm for the 1000 dataset\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svm_1000 = svc.predict(X_test)\n",
    "accuracy_svm_1000 = accuracy_score(y_test, y_pred_svm_1000)\n",
    "recall_svm_1000 = recall_score(y_test, y_pred_svm_1000)\n",
    "prec_svm_1000 = precision_score(y_test, y_pred_svm_1000)\n",
    "cm_svm_1000 = confusion_matrix(y_test, y_pred_svm_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest for the 1000 dataset\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf_1000 = rf.predict(X_test)\n",
    "y_pred_proba_rf_1000 = rf.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_rf_1000 = accuracy_score(y_test, y_pred_rf_1000)\n",
    "recall_rf_1000 = recall_score(y_test, y_pred_rf_1000)\n",
    "prec_rf_1000 = precision_score(y_test, y_pred_rf_1000)\n",
    "cm_rf_1000 = confusion_matrix(y_test, y_pred_rf_1000)\n",
    "auc_rf_1000 = roc_auc_score(y_test, y_pred_proba_rf_1000)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regr for the 1000 dataset\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr_1000 = lr.predict(X_test)\n",
    "y_pred_proba_lr_1000 = lr.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_lr_1000 = accuracy_score(y_test, y_pred_lr_1000)\n",
    "recall_lr_1000 = recall_score(y_test, y_pred_lr_1000)\n",
    "prec_lr_1000 = precision_score(y_test, y_pred_lr_1000)\n",
    "cm_lr_1000 = confusion_matrix(y_test, y_pred_lr_1000)\n",
    "auc_lr_1000 = roc_auc_score(y_test, y_pred_proba_lr_1000)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision trees for the 1000 dataset\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt_1000 = dt.predict(X_test)\n",
    "y_pred_proba_dt_1000 = dt.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_dt_1000 = accuracy_score(y_test, y_pred_dt_1000)\n",
    "recall_dt_1000 = recall_score(y_test, y_pred_dt_1000)\n",
    "prec_dt_1000 = precision_score(y_test, y_pred_dt_1000)\n",
    "cm_dt_1000 = confusion_matrix(y_test, y_pred_dt_1000)\n",
    "auc_dt_1000 = roc_auc_score(y_test, y_pred_proba_dt_1000)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 1000 from the whole train dataset, n = 6 features\n",
    "data_class_0 = train[train['Y'] == 0][:1000]  # slice only 1000 rows \n",
    "data_class_1 = train[train['Y'] == 1]\n",
    "df_1000 = data_class_0.append(data_class_1)  # reduced train set with 1000 '0' rows and all '1' rows\n",
    "X_train = df_1000.loc[:, features].values\n",
    "y_train = df_1000.loc[:,['Y']].values\n",
    "X_test = test.loc[:, features].values\n",
    "y_test = test.loc[:,['Y']].values\n",
    "\n",
    "pca = PCA(n_components=6)  # specify num of features to keep\n",
    "pca.fit(X_train)\n",
    "ratio_1000 = pca.explained_variance_ratio_\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "y_train = y_train.ravel() # transform to numpy array\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn for the 1000 dataset, 6 features\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn_1000_6 = knn.predict(X_test)\n",
    "y_pred_proba_knn_1000_6 = knn.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_knn_1000_6 = accuracy_score(y_test, y_pred_knn_1000_6)\n",
    "recall_knn_1000_6 = recall_score(y_test, y_pred_knn_1000_6)\n",
    "prec_knn_1000_6 = precision_score(y_test, y_pred_knn_1000_6)\n",
    "cm_knn_1000_6 = confusion_matrix(y_test, y_pred_knn_1000_6)\n",
    "auc_knn_1000_6 = roc_auc_score(y_test, y_pred_proba_knn_1000_6)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm for the 1000 dataset, 6 features\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svm_1000_6 = svc.predict(X_test)\n",
    "accuracy_svm_1000_6 = accuracy_score(y_test, y_pred_svm_1000_6)\n",
    "recall_svm_1000_6 = recall_score(y_test, y_pred_svm_1000_6)\n",
    "prec_svm_1000_6 = precision_score(y_test, y_pred_svm_1000_6)\n",
    "cm_svm_1000_6 = confusion_matrix(y_test, y_pred_svm_1000_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest for the 1000 dataset, 6 features\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf_1000_6 = rf.predict(X_test)\n",
    "y_pred_proba_rf_1000_6 = rf.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_rf_1000_6 = accuracy_score(y_test, y_pred_rf_1000_6)\n",
    "recall_rf_1000_6 = recall_score(y_test, y_pred_rf_1000_6)\n",
    "prec_rf_1000_6 = precision_score(y_test, y_pred_rf_1000_6)\n",
    "cm_rf_1000_6 = confusion_matrix(y_test, y_pred_rf_1000_6)\n",
    "auc_rf_1000_6 = roc_auc_score(y_test, y_pred_proba_rf_1000_6)  # AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regr for the 1000 dataset, 6 features\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr_1000_6 = lr.predict(X_test)\n",
    "y_pred_proba_lr_1000_6 = lr.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_lr_1000_6 = accuracy_score(y_test, y_pred_lr_1000_6)\n",
    "recall_lr_1000_6 = recall_score(y_test, y_pred_lr_1000_6)\n",
    "prec_lr_1000_6 = precision_score(y_test, y_pred_lr_1000_6)\n",
    "cm_lr_1000_6 = confusion_matrix(y_test, y_pred_lr_1000_6)\n",
    "auc_lr_1000_6 = roc_auc_score(y_test, y_pred_proba_lr_1000_6)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision trees for the 1000 dataset, 6 features\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt_1000_6 = dt.predict(X_test)\n",
    "y_pred_proba_dt_1000_6 = dt.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_dt_1000_6 = accuracy_score(y_test, y_pred_dt_1000_6)\n",
    "recall_dt_1000_6 = recall_score(y_test, y_pred_dt_1000_6)\n",
    "prec_dt_1000_6 = precision_score(y_test, y_pred_dt_1000_6)\n",
    "cm_dt_1000_6 = confusion_matrix(y_test, y_pred_dt_1000_6)\n",
    "auc_dt_1000_6 = roc_auc_score(y_test, y_pred_proba_dt_1000_6)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 1000 from the whole train dataset, n = 5 features\n",
    "data_class_0 = train[train['Y'] == 0][:1000]  # slice only 1000 rows \n",
    "data_class_1 = train[train['Y'] == 1]\n",
    "df_1000 = data_class_0.append(data_class_1)  # reduced train set with 1000 '0' rows and all '1' rows\n",
    "X_train = df_1000.loc[:, features].values\n",
    "y_train = df_1000.loc[:,['Y']].values\n",
    "X_test = test.loc[:, features].values\n",
    "y_test = test.loc[:,['Y']].values\n",
    "\n",
    "pca = PCA(n_components=5)  # specify num of features to keep\n",
    "pca.fit(X_train)\n",
    "ratio_1000 = pca.explained_variance_ratio_\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "y_train = y_train.ravel() # transform to numpy array\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn for the 1000 dataset, 5 features\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn_1000_5 = knn.predict(X_test)\n",
    "y_pred_proba_knn_1000_5 = knn.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_knn_1000_5 = accuracy_score(y_test, y_pred_knn_1000_5)\n",
    "recall_knn_1000_5 = recall_score(y_test, y_pred_knn_1000_5)\n",
    "prec_knn_1000_5 = precision_score(y_test, y_pred_knn_1000_5)\n",
    "cm_knn_1000_5 = confusion_matrix(y_test, y_pred_knn_1000_5)\n",
    "auc_knn_1000_5 = roc_auc_score(y_test, y_pred_proba_knn_1000_5)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm for the 1000 dataset, 5 features\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svm_1000_5 = svc.predict(X_test)\n",
    "accuracy_svm_1000_5 = accuracy_score(y_test, y_pred_svm_1000_5)\n",
    "recall_svm_1000_5 = recall_score(y_test, y_pred_svm_1000_5)\n",
    "prec_svm_1000_5 = precision_score(y_test, y_pred_svm_1000_5)\n",
    "cm_svm_1000_5 = confusion_matrix(y_test, y_pred_svm_1000_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest for the 1000 dataset, 5 features\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf_1000_5 = rf.predict(X_test)\n",
    "y_pred_proba_rf_1000_5 = rf.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_rf_1000_5 = accuracy_score(y_test, y_pred_rf_1000_5)\n",
    "recall_rf_1000_5 = recall_score(y_test, y_pred_rf_1000_5)\n",
    "prec_rf_1000_5 = precision_score(y_test, y_pred_rf_1000_5)\n",
    "cm_rf_1000_5 = confusion_matrix(y_test, y_pred_rf_1000_5)\n",
    "auc_rf_1000_5 = roc_auc_score(y_test, y_pred_proba_rf_1000_5)  # AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regr for the 1000 dataset, 5 features\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr_1000_5 = lr.predict(X_test)\n",
    "y_pred_proba_lr_1000_5 = lr.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_lr_1000_5 = accuracy_score(y_test, y_pred_lr_1000_5)\n",
    "recall_lr_1000_5 = recall_score(y_test, y_pred_lr_1000_5)\n",
    "prec_lr_1000_5 = precision_score(y_test, y_pred_lr_1000_5)\n",
    "cm_lr_1000_5 = confusion_matrix(y_test, y_pred_lr_1000_5)\n",
    "auc_lr_1000_5 = roc_auc_score(y_test, y_pred_proba_lr_1000_5)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision trees for the 1000 dataset, 5 features\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt_1000_5 = dt.predict(X_test)\n",
    "y_pred_proba_dt_1000_5 = dt.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_dt_1000_5 = accuracy_score(y_test, y_pred_dt_1000_5)\n",
    "recall_dt_1000_5 = recall_score(y_test, y_pred_dt_1000_5)\n",
    "prec_dt_1000_5 = precision_score(y_test, y_pred_dt_1000_5)\n",
    "cm_dt_1000_5 = confusion_matrix(y_test, y_pred_dt_1000_5)\n",
    "auc_dt_1000_5 = roc_auc_score(y_test, y_pred_proba_dt_1000_5)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 1000 from the whole train dataset, n = 4 features\n",
    "data_class_0 = train[train['Y'] == 0][:1000]  # slice only 1000 rows \n",
    "data_class_1 = train[train['Y'] == 1]\n",
    "df_1000 = data_class_0.append(data_class_1)  # reduced train set with 1000 '0' rows and all '1' rows\n",
    "X_train = df_1000.loc[:, features].values\n",
    "y_train = df_1000.loc[:,['Y']].values\n",
    "X_test = test.loc[:, features].values\n",
    "y_test = test.loc[:,['Y']].values\n",
    "\n",
    "pca = PCA(n_components=4)  # specify num of features to keep\n",
    "pca.fit(X_train)\n",
    "ratio_1000 = pca.explained_variance_ratio_\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "y_train = y_train.ravel() # transform to numpy array\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn for the 1000 dataset, 4 features\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn_1000_4 = knn.predict(X_test)\n",
    "y_pred_proba_knn_1000_4 = knn.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_knn_1000_4 = accuracy_score(y_test, y_pred_knn_1000_4)\n",
    "recall_knn_1000_4 = recall_score(y_test, y_pred_knn_1000_4)\n",
    "prec_knn_1000_4 = precision_score(y_test, y_pred_knn_1000_4)\n",
    "cm_knn_1000_4 = confusion_matrix(y_test, y_pred_knn_1000_4)\n",
    "auc_knn_1000_4 = roc_auc_score(y_test, y_pred_proba_knn_1000_4)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm for the 1000 dataset, 4 features\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svm_1000_4 = svc.predict(X_test)\n",
    "accuracy_svm_1000_4 = accuracy_score(y_test, y_pred_svm_1000_4)\n",
    "recall_svm_1000_4 = recall_score(y_test, y_pred_svm_1000_4)\n",
    "prec_svm_1000_4 = precision_score(y_test, y_pred_svm_1000_4)\n",
    "cm_svm_1000_4 = confusion_matrix(y_test, y_pred_svm_1000_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest for the 1000 dataset, 4 features\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf_1000_4 = rf.predict(X_test)\n",
    "y_pred_proba_rf_1000_4 = rf.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_rf_1000_4 = accuracy_score(y_test, y_pred_rf_1000_4)\n",
    "recall_rf_1000_4 = recall_score(y_test, y_pred_rf_1000_4)\n",
    "prec_rf_1000_4 = precision_score(y_test, y_pred_rf_1000_4)\n",
    "cm_rf_1000_4 = confusion_matrix(y_test, y_pred_rf_1000_4)\n",
    "auc_rf_1000_4 = roc_auc_score(y_test, y_pred_proba_rf_1000_4)  # AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regr for the 1000 dataset, 4 features\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr_1000_4 = lr.predict(X_test)\n",
    "y_pred_proba_lr_1000_4 = lr.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_lr_1000_4 = accuracy_score(y_test, y_pred_lr_1000_4)\n",
    "recall_lr_1000_4 = recall_score(y_test, y_pred_lr_1000_4)\n",
    "prec_lr_1000_4 = precision_score(y_test, y_pred_lr_1000_4)\n",
    "cm_lr_1000_4 = confusion_matrix(y_test, y_pred_lr_1000_4)\n",
    "auc_lr_1000_4 = roc_auc_score(y_test, y_pred_proba_lr_1000_4)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision trees for the 1000 dataset, 4 features\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt_1000_4 = dt.predict(X_test)\n",
    "y_pred_proba_dt_1000_4 = dt.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_dt_1000_4 = accuracy_score(y_test, y_pred_dt_1000_4)\n",
    "recall_dt_1000_4 = recall_score(y_test, y_pred_dt_1000_4)\n",
    "prec_dt_1000_4 = precision_score(y_test, y_pred_dt_1000_4)\n",
    "cm_dt_1000_4 = confusion_matrix(y_test, y_pred_dt_1000_4)\n",
    "auc_dt_1000_4 = roc_auc_score(y_test, y_pred_proba_dt_1000_4)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 1000 from the whole train dataset, n = 3 features\n",
    "data_class_0 = train[train['Y'] == 0][:1000]  # slice only 1000 rows \n",
    "data_class_1 = train[train['Y'] == 1]\n",
    "df_1000 = data_class_0.append(data_class_1)  # reduced train set with 1000 '0' rows and all '1' rows\n",
    "X_train = df_1000.loc[:, features].values\n",
    "y_train = df_1000.loc[:,['Y']].values\n",
    "X_test = test.loc[:, features].values\n",
    "y_test = test.loc[:,['Y']].values\n",
    "\n",
    "pca = PCA(n_components=3)  # specify num of features to keep\n",
    "pca.fit(X_train)\n",
    "ratio_1000 = pca.explained_variance_ratio_\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "y_train = y_train.ravel() # transform to numpy array\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn for the 1000 dataset, 3 features\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn_1000_3 = knn.predict(X_test)\n",
    "y_pred_proba_knn_1000_3 = knn.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_knn_1000_3 = accuracy_score(y_test, y_pred_knn_1000_3)\n",
    "recall_knn_1000_3 = recall_score(y_test, y_pred_knn_1000_3)\n",
    "prec_knn_1000_3 = precision_score(y_test, y_pred_knn_1000_3)\n",
    "cm_knn_1000_3 = confusion_matrix(y_test, y_pred_knn_1000_3)\n",
    "auc_knn_1000_3 = roc_auc_score(y_test, y_pred_proba_knn_1000_3)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm for the 1000 dataset, 3 features\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svm_1000_3 = svc.predict(X_test)\n",
    "accuracy_svm_1000_3 = accuracy_score(y_test, y_pred_svm_1000_3)\n",
    "recall_svm_1000_3 = recall_score(y_test, y_pred_svm_1000_3)\n",
    "prec_svm_1000_3 = precision_score(y_test, y_pred_svm_1000_3)\n",
    "cm_svm_1000_3 = confusion_matrix(y_test, y_pred_svm_1000_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest for the 1000 dataset, 3 features\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf_1000_3 = rf.predict(X_test)\n",
    "y_pred_proba_rf_1000_3 = rf.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_rf_1000_3 = accuracy_score(y_test, y_pred_rf_1000_3)\n",
    "recall_rf_1000_3 = recall_score(y_test, y_pred_rf_1000_3)\n",
    "prec_rf_1000_3 = precision_score(y_test, y_pred_rf_1000_3)\n",
    "cm_rf_1000_3 = confusion_matrix(y_test, y_pred_rf_1000_3)\n",
    "auc_rf_1000_3 = roc_auc_score(y_test, y_pred_proba_rf_1000_3)  # AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regr for the 1000 dataset, 3 features\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr_1000_3 = lr.predict(X_test)\n",
    "y_pred_proba_lr_1000_3 = lr.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_lr_1000_3 = accuracy_score(y_test, y_pred_lr_1000_3)\n",
    "recall_lr_1000_3 = recall_score(y_test, y_pred_lr_1000_3)\n",
    "prec_lr_1000_3 = precision_score(y_test, y_pred_lr_1000_3)\n",
    "cm_lr_1000_3 = confusion_matrix(y_test, y_pred_lr_1000_3)\n",
    "auc_lr_1000_3 = roc_auc_score(y_test, y_pred_proba_lr_1000_3)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision trees for the 1000 dataset, 3 features\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt_1000_3 = dt.predict(X_test)\n",
    "y_pred_proba_dt_1000_3 = dt.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_dt_1000_3 = accuracy_score(y_test, y_pred_dt_1000_3)\n",
    "recall_dt_1000_3 = recall_score(y_test, y_pred_dt_1000_3)\n",
    "prec_dt_1000_3 = precision_score(y_test, y_pred_dt_1000_3)\n",
    "cm_dt_1000_3 = confusion_matrix(y_test, y_pred_dt_1000_3)\n",
    "auc_dt_1000_3 = roc_auc_score(y_test, y_pred_proba_dt_1000_3)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample: 1000 from the whole train dataset, n = 2 features\n",
    "data_class_0 = train[train['Y'] == 0][:1000]  # slice only 1000 rows \n",
    "data_class_1 = train[train['Y'] == 1]\n",
    "df_1000 = data_class_0.append(data_class_1)  # reduced train set with 1000 '0' rows and all '1' rows\n",
    "X_train = df_1000.loc[:, features].values\n",
    "y_train = df_1000.loc[:,['Y']].values\n",
    "X_test = test.loc[:, features].values\n",
    "y_test = test.loc[:,['Y']].values\n",
    "\n",
    "pca = PCA(n_components=2)  # specify num of features to keep\n",
    "pca.fit(X_train)\n",
    "ratio_1000 = pca.explained_variance_ratio_\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "y_train = y_train.ravel() # transform to numpy array\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn for the 1000 dataset, 2 features\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn_1000_2 = knn.predict(X_test)\n",
    "y_pred_proba_knn_1000_2 = knn.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_knn_1000_2 = accuracy_score(y_test, y_pred_knn_1000_2)\n",
    "recall_knn_1000_2 = recall_score(y_test, y_pred_knn_1000_2)\n",
    "prec_knn_1000_2 = precision_score(y_test, y_pred_knn_1000_2)\n",
    "cm_knn_1000_2 = confusion_matrix(y_test, y_pred_knn_1000_2)\n",
    "auc_knn_1000_2 = roc_auc_score(y_test, y_pred_proba_knn_1000_2)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm for the 1000 dataset, 2 features\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svm_1000_2 = svc.predict(X_test)\n",
    "accuracy_svm_1000_2 = accuracy_score(y_test, y_pred_svm_1000_2)\n",
    "recall_svm_1000_2 = recall_score(y_test, y_pred_svm_1000_2)\n",
    "prec_svm_1000_2 = precision_score(y_test, y_pred_svm_1000_2)\n",
    "cm_svm_1000_2 = confusion_matrix(y_test, y_pred_svm_1000_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest for the 1000 dataset, 2 features\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf_1000_2 = rf.predict(X_test)\n",
    "y_pred_proba_rf_1000_2 = rf.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_rf_1000_2 = accuracy_score(y_test, y_pred_rf_1000_2)\n",
    "recall_rf_1000_2 = recall_score(y_test, y_pred_rf_1000_2)\n",
    "prec_rf_1000_2 = precision_score(y_test, y_pred_rf_1000_2)\n",
    "cm_rf_1000_2 = confusion_matrix(y_test, y_pred_rf_1000_2)\n",
    "auc_rf_1000_2 = roc_auc_score(y_test, y_pred_proba_rf_1000_2)  # AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regr for the 1000 dataset, 2 features\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr_1000_2 = lr.predict(X_test)\n",
    "y_pred_proba_lr_1000_2 = lr.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_lr_1000_2 = accuracy_score(y_test, y_pred_lr_1000_2)\n",
    "recall_lr_1000_2 = recall_score(y_test, y_pred_lr_1000_2)\n",
    "prec_lr_1000_2 = precision_score(y_test, y_pred_lr_1000_2)\n",
    "cm_lr_1000_2 = confusion_matrix(y_test, y_pred_lr_1000_2)\n",
    "auc_lr_1000_2 = roc_auc_score(y_test, y_pred_proba_lr_1000_2)  # AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision trees for the 1000 dataset, 2 features\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt_1000_2 = dt.predict(X_test)\n",
    "y_pred_proba_dt_1000_2 = dt.predict_proba(X_test)[:,1]  # compute probabilities\n",
    "accuracy_dt_1000_2 = accuracy_score(y_test, y_pred_dt_1000_2)\n",
    "recall_dt_1000_2 = recall_score(y_test, y_pred_dt_1000_2)\n",
    "prec_dt_1000_2 = precision_score(y_test, y_pred_dt_1000_2)\n",
    "cm_dt_1000_2 = confusion_matrix(y_test, y_pred_dt_1000_2)\n",
    "auc_dt_1000_2 = roc_auc_score(y_test, y_pred_proba_dt_1000_2)  # AUC "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
